import { Rwkv, RwkvInvocation } from '@llama-node/rwkv-cpp';
import { ILLM, LLMResult } from './type.js';

interface LoadConfig {
    modelPath: string;
    tokenizerPath: string;
    nThreads: number;
    enableLogging: boolean;
}
interface TokenizeArguments {
    content: string;
}
declare class RwkvCpp implements ILLM<Rwkv, LoadConfig, RwkvInvocation, unknown, TokenizeArguments> {
    instance: Rwkv;
    load(config: LoadConfig): Promise<void>;
    createCompletion(params: RwkvInvocation, callback: (data: {
        token: string;
        completed: boolean;
    }) => void, abortSignal?: AbortSignal): Promise<LLMResult>;
    tokenize(params: TokenizeArguments): Promise<number[]>;
}

export { LoadConfig, RwkvCpp, TokenizeArguments };
