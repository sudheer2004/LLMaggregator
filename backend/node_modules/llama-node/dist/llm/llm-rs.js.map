{"version":3,"sources":["../../src/llm/llm-rs.ts","../../src/llm/type.ts"],"sourcesContent":["import {\n    InferenceResultType,\n    Llm,\n    ModelLoad,\n    Generate,\n} from \"@llama-node/core\";\n\nimport { type ILLM, type LLMResult, LLMError, LLMErrorType } from \"./type\";\n\nexport interface LoadConfig extends ModelLoad {\n    enableLogging?: boolean;\n}\n\nexport class LLMRS implements ILLM<Llm, ModelLoad, Generate, Generate, string> {\n    instance!: Llm;\n\n    async load(config: LoadConfig) {\n        const { enableLogging, ...rest } = config;\n        this.instance = await Llm.load(rest, enableLogging ?? true);\n    }\n\n    async createCompletion(\n        params: Partial<Generate>,\n        callback: (data: { token: string; completed: boolean }) => void,\n        abortSignal?: AbortSignal\n    ): Promise<LLMResult> {\n        let completed = false;\n        const tokens: string[] = [];\n        const errors: string[] = [];\n        return new Promise<LLMResult>(\n            (res, rej: (reason: LLMError) => void) => {\n                const abort = this.instance.inference(params, (response) => {\n                    switch (response.type) {\n                        case InferenceResultType.Data: {\n                            const data = {\n                                token: response.data!.token,\n                                completed: !!response.data!.completed,\n                            };\n                            tokens.push(data.token);\n                            if (data.completed) {\n                                completed = true;\n                            }\n                            callback(data);\n                            break;\n                        }\n                        case InferenceResultType.End: {\n                            if (errors.length) {\n                                rej(\n                                    new LLMError({\n                                        message: errors.join(\"\\n\"),\n                                        tokens,\n                                        completed,\n                                        type: LLMErrorType.Generic,\n                                    })\n                                );\n                            } else {\n                                res({ tokens, completed });\n                            }\n                            break;\n                        }\n                        case InferenceResultType.Error: {\n                            errors.push(response.message ?? \"Unknown error\");\n                            break;\n                        }\n                    }\n                });\n\n                const abortSignalHandler = () => {\n                    abort();\n                    rej(\n                        new LLMError({\n                            message: \"Aborted\",\n                            tokens,\n                            completed,\n                            type: LLMErrorType.Aborted,\n                        })\n                    );\n                    abortSignal?.removeEventListener(\n                        \"abort\",\n                        abortSignalHandler\n                    );\n                };\n\n                abortSignal?.addEventListener(\"abort\", abortSignalHandler);\n            }\n        );\n    }\n\n    async getEmbedding(params: Partial<Generate>): Promise<number[]> {\n        return await this.instance.getWordEmbeddings(params);\n    }\n\n    async getDefaultEmbedding(text: string): Promise<number[]> {\n        return this.getEmbedding({\n            numPredict: 1024,\n            topK: 40,\n            topP: 0.1,\n            repeatPenalty: 1,\n            prompt: text,\n        });\n    }\n\n    async tokenize(params: string): Promise<number[]> {\n        return await this.instance.tokenize(params);\n    }\n}\n","export interface CompletionCallback {\n    (data: { token: string; completed: boolean }): void;\n}\n\nexport interface ILLM<\n    Instance,\n    LoadConfig,\n    LLMInferenceArguments,\n    LLMEmbeddingArguments,\n    LLMTokenizeArguments\n> {\n    readonly instance: Instance;\n\n    load(config: LoadConfig): Promise<void>;\n\n    createCompletion(\n        params: LLMInferenceArguments,\n        callback: CompletionCallback,\n        abortSignal?: AbortSignal\n    ): Promise<LLMResult>;\n\n    getEmbedding?(params: LLMEmbeddingArguments): Promise<number[]>;\n\n    getDefaultEmbedding?(text: string): Promise<number[]>;\n\n    tokenize?(content: LLMTokenizeArguments): Promise<number[]>;\n}\n\nexport interface LLMResult {\n    tokens: string[];\n    completed: boolean;\n}\n\nexport enum LLMErrorType {\n    Aborted = \"Aborted\",\n    Generic = \"Generic\",\n}\n\nexport class LLMError extends Error {\n    public readonly tokens: string[];\n    public readonly completed: boolean;\n    public readonly type: LLMErrorType;\n\n    constructor({\n        message,\n        tokens,\n        completed,\n        type,\n    }: {\n        message: string;\n        tokens: string[];\n        completed: boolean;\n        type: LLMErrorType;\n    }) {\n        super(message);\n        this.tokens = tokens;\n        this.completed = completed;\n        this.type = type;\n    }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA,EACI;AAAA,EACA;AAAA,OAGG;;;ACiCA,IAAM,WAAN,cAAuB,MAAM;AAAA,EAKhC,YAAY;AAAA,IACR;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACJ,GAKG;AACC,UAAM,OAAO;AACb,SAAK,SAAS;AACd,SAAK,YAAY;AACjB,SAAK,OAAO;AAAA,EAChB;AACJ;;;AD9CO,IAAM,QAAN,MAAwE;AAAA,EAGrE,KAAK,QAAoB;AAAA;AAC3B,YAAmC,aAA3B,gBAjBhB,IAiB2C,IAAT,iBAAS,IAAT,CAAlB;AACR,WAAK,WAAW,MAAM,IAAI,KAAK,MAAM,wCAAiB,IAAI;AAAA,IAC9D;AAAA;AAAA,EAEM,iBACF,QACA,UACA,aACkB;AAAA;AAClB,UAAI,YAAY;AAChB,YAAM,SAAmB,CAAC;AAC1B,YAAM,SAAmB,CAAC;AAC1B,aAAO,IAAI;AAAA,QACP,CAAC,KAAK,QAAoC;AACtC,gBAAM,QAAQ,KAAK,SAAS,UAAU,QAAQ,CAAC,aAAa;AA/B5E;AAgCoB,oBAAQ,SAAS,MAAM;AAAA,cACnB,KAAK,oBAAoB,MAAM;AAC3B,sBAAM,OAAO;AAAA,kBACT,OAAO,SAAS,KAAM;AAAA,kBACtB,WAAW,CAAC,CAAC,SAAS,KAAM;AAAA,gBAChC;AACA,uBAAO,KAAK,KAAK,KAAK;AACtB,oBAAI,KAAK,WAAW;AAChB,8BAAY;AAAA,gBAChB;AACA,yBAAS,IAAI;AACb;AAAA,cACJ;AAAA,cACA,KAAK,oBAAoB,KAAK;AAC1B,oBAAI,OAAO,QAAQ;AACf;AAAA,oBACI,IAAI,SAAS;AAAA,sBACT,SAAS,OAAO,KAAK,IAAI;AAAA,sBACzB;AAAA,sBACA;AAAA,sBACA;AAAA,oBACJ,CAAC;AAAA,kBACL;AAAA,gBACJ,OAAO;AACH,sBAAI,EAAE,QAAQ,UAAU,CAAC;AAAA,gBAC7B;AACA;AAAA,cACJ;AAAA,cACA,KAAK,oBAAoB,OAAO;AAC5B,uBAAO,MAAK,cAAS,YAAT,YAAoB,eAAe;AAC/C;AAAA,cACJ;AAAA,YACJ;AAAA,UACJ,CAAC;AAED,gBAAM,qBAAqB,MAAM;AAC7B,kBAAM;AACN;AAAA,cACI,IAAI,SAAS;AAAA,gBACT,SAAS;AAAA,gBACT;AAAA,gBACA;AAAA,gBACA;AAAA,cACJ,CAAC;AAAA,YACL;AACA,uDAAa;AAAA,cACT;AAAA,cACA;AAAA;AAAA,UAER;AAEA,qDAAa,iBAAiB,SAAS;AAAA,QAC3C;AAAA,MACJ;AAAA,IACJ;AAAA;AAAA,EAEM,aAAa,QAA8C;AAAA;AAC7D,aAAO,MAAM,KAAK,SAAS,kBAAkB,MAAM;AAAA,IACvD;AAAA;AAAA,EAEM,oBAAoB,MAAiC;AAAA;AACvD,aAAO,KAAK,aAAa;AAAA,QACrB,YAAY;AAAA,QACZ,MAAM;AAAA,QACN,MAAM;AAAA,QACN,eAAe;AAAA,QACf,QAAQ;AAAA,MACZ,CAAC;AAAA,IACL;AAAA;AAAA,EAEM,SAAS,QAAmC;AAAA;AAC9C,aAAO,MAAM,KAAK,SAAS,SAAS,MAAM;AAAA,IAC9C;AAAA;AACJ;","names":[]}