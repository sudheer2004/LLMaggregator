import { ModelLoad, Llm, Generate } from '@llama-node/core';
import { ILLM, LLMResult } from './type.js';

interface LoadConfig extends ModelLoad {
    enableLogging?: boolean;
}
declare class LLMRS implements ILLM<Llm, ModelLoad, Generate, Generate, string> {
    instance: Llm;
    load(config: LoadConfig): Promise<void>;
    createCompletion(params: Partial<Generate>, callback: (data: {
        token: string;
        completed: boolean;
    }) => void, abortSignal?: AbortSignal): Promise<LLMResult>;
    getEmbedding(params: Partial<Generate>): Promise<number[]>;
    getDefaultEmbedding(text: string): Promise<number[]>;
    tokenize(params: string): Promise<number[]>;
}

export { LLMRS, LoadConfig };
